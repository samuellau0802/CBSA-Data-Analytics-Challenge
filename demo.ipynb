{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"sample_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>【內地調查：疫情對中國住宿和餐飲行業影響最大】        中新社報道，上海國家會計學院會...</td>\n",
       "      <td>0</td>\n",
       "      <td>【 內地 調查 ： 疫情 對 中國 住宿 和 餐 飲行業 影響 最大 】          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168447</th>\n",
       "      <td>【香港青年協會未來技能博覽】「疫情時代與STEM教育前瞻」分享會 疫情持續，令人反思未來的教...</td>\n",
       "      <td>0</td>\n",
       "      <td>【 香港 青年 協會 未來 技能 博覽 】 「 疫情 時代 與 STEM 教育 前瞻 」 分...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "7851    【內地調查：疫情對中國住宿和餐飲行業影響最大】        中新社報道，上海國家會計學院會...      0   \n",
       "168447  【香港青年協會未來技能博覽】「疫情時代與STEM教育前瞻」分享會 疫情持續，令人反思未來的教...      0   \n",
       "\n",
       "                                          tokenized_words  \n",
       "7851    【 內地 調查 ： 疫情 對 中國 住宿 和 餐 飲行業 影響 最大 】          ...  \n",
       "168447  【 香港 青年 協會 未來 技能 博覽 】 「 疫情 時代 與 STEM 教育 前瞻 」 分...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'tokenized_words': 'tokenized_text'},\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(list(df['tokenized_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<110767x611393 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14659224 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NaiveBayes.py\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classifier = ComplementNB()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.25)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predict_test = classifier.predict(X_test)\n",
    "#accuracy_test = f1_score(y_test,predict_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.31      0.42      1685\n",
      "           2       0.73      0.60      0.66      1988\n",
      "           3       0.74      0.87      0.80      3889\n",
      "           4       0.80      0.73      0.76      2962\n",
      "           5       0.81      0.61      0.70       655\n",
      "           6       0.72      0.87      0.79      3367\n",
      "           7       0.79      0.86      0.82      2566\n",
      "           8       0.91      0.18      0.30       288\n",
      "           9       0.78      0.47      0.59      1104\n",
      "          10       0.59      0.84      0.69      4416\n",
      "          11       0.83      0.37      0.51      1070\n",
      "          12       0.89      0.25      0.39       978\n",
      "          13       0.68      0.86      0.76      1829\n",
      "          14       0.93      0.26      0.40       248\n",
      "          15       0.77      0.54      0.63       647\n",
      "\n",
      "    accuracy                           0.71     27692\n",
      "   macro avg       0.78      0.57      0.61     27692\n",
      "weighted avg       0.73      0.71      0.69     27692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\CBSA\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Desktop\\CBSA\\CBSA-Data-Analytics-Challenge\\demo.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/demo.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mXGModels\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/demo.ipynb#ch0000010?line=2'>3</a>\u001b[0m model, preds \u001b[39m=\u001b[39m XG_Classifier(X, df[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\samue\\Desktop\\CBSA\\CBSA-Data-Analytics-Challenge\\XGModels.py:34\u001b[0m, in \u001b[0;36mXG_Classifier\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/XGModels.py?line=30'>31</a>\u001b[0m xgbclassify\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='file:///c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/XGModels.py?line=31'>32</a>\u001b[0m preds \u001b[39m=\u001b[39m xgbclassify\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> <a href='file:///c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/XGModels.py?line=33'>34</a>\u001b[0m score \u001b[39m=\u001b[39m f1_score(y_test, preds)\n\u001b[0;32m     <a href='file:///c%3A/Users/samue/Desktop/CBSA/CBSA-Data-Analytics-Challenge/XGModels.py?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m xgbclassify, score\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CBSA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1123\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=991'>992</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=992'>993</a>\u001b[0m     y_true,\n\u001b[0;32m    <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=993'>994</a>\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=999'>1000</a>\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1000'>1001</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1001'>1002</a>\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1002'>1003</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1003'>1004</a>\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1120'>1121</a>\u001b[0m \u001b[39m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1121'>1122</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1122'>1123</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1123'>1124</a>\u001b[0m         y_true,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1124'>1125</a>\u001b[0m         y_pred,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1125'>1126</a>\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1126'>1127</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1127'>1128</a>\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1128'>1129</a>\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1129'>1130</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1130'>1131</a>\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1131'>1132</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CBSA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1261\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1134'>1135</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1135'>1136</a>\u001b[0m     y_true,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1136'>1137</a>\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1143'>1144</a>\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1144'>1145</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1145'>1146</a>\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1146'>1147</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1147'>1148</a>\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1257'>1258</a>\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1258'>1259</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1260'>1261</a>\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1261'>1262</a>\u001b[0m         y_true,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1262'>1263</a>\u001b[0m         y_pred,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1263'>1264</a>\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1264'>1265</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1265'>1266</a>\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1266'>1267</a>\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1267'>1268</a>\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1268'>1269</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1269'>1270</a>\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1270'>1271</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1271'>1272</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CBSA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1541'>1542</a>\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1542'>1543</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1543'>1544</a>\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1545'>1546</a>\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1546'>1547</a>\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CBSA\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1362'>1363</a>\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1363'>1364</a>\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1364'>1365</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1365'>1366</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1366'>1367</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1367'>1368</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1368'>1369</a>\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1369'>1370</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1370'>1371</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1371'>1372</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1374'>1375</a>\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/samue/anaconda3/envs/CBSA/lib/site-packages/sklearn/metrics/_classification.py?line=1375'>1376</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from XGModels import *\n",
    "\n",
    "model, preds = XG_Classifier(X, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "429eaa20eb89031f90b5471057c6d0da4fa07055a4a0bea2a60f1417be95d314"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('CBSA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
